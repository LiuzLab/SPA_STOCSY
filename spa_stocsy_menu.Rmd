---
title: "SPA_STOCSY_menu"
output:
  html_document:
    theme: united
    toc: yes
    toc_depth: 4
    toc_float:
      collapsed: yes
  pdf_document:
    toc: yes
    toc_depth: '4'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(baseline)
library(msProcess)
library(splus2R)

```


## Setup codes
```{r}
##specify paths to load the source codes, input data and save the output files
code_dir <- "~/Desktop/SPA-STOCSY/submit_github/source_codes/"
data_dir <- "~/Desktop/SPA-STOCSY/submit_github/input_data/"
output_dir <- "~/Desktop/SPA-STOCSY/submit_github/output/"

setwd(code_dir)

{ source("align.r")
  source("Auto_dect_one.r")
  source("baseline_removal.r")
  source("Build_new.r")
  source("clus.r")
  source("clus_region.r")
  source("Clust.member.r")
  source("combine_cluster_peak.r")
  source("cor_landscape.r")
  source("Cor.stat.r")
  source("Epane_kern.r")
  source("FindMeta.r")
  source("ftn.r")
  source("Gen_co_member.r")
  source("gen_SPA_peaks.r")
  source("gen_stocsy_corr_clusters.r")
  source("gen_summary_profile.r")
  source("Gen.ct.r")
  source("gen.J.couple.r")
  source("Gen.spa.group.R")
 
  source("Ints_avg_mod.r")
  source("Landscape_cut.r")
  source("ms_peak.r")
  source("myImagePlot2.r")
  source("Noise.estimate.r")
  source("norm_kern.r")

  source("peaks.correct.r")
  source("peak_detection_cwt.r")
  source("Peak_simple.r")
  source("PkinReg.r")
  source("plot_pred.streth.r")
  source("PQ_norm_signal.r")
  source("pred.strength.r")

  source("Select.gam.r")
  source("tri_cube_kern.r")


  }
```


##Load input data
###Set file path
```{r}

setwd(data_dir)
filename = "htt_c12.csv" 
htt.dat <- read.csv(filename, header = T)
```

###Extract ppm and adjust data format
```{r}
ppm0 <- htt.dat[,1]
dat0 <- t(htt.dat[, -1])
avg <- apply(dat0, 2, mean)

n.tr <- dim(dat0)[1]/2
n.cv <- 10
```

```{r,echo=FALSE}
print("Head of data:")
print(dat0[1:5,1:5])
print("Raw data loaded.")
```


##Raw data preprocessing steps:
###Samples alignment:
```{r}
region = c(-.05, .05)
ppm = ppm0
##find alignment marker
ali.mark =  ppm[which.min(abs(ppm))]
dat = dat0

##use Align function
ares <- Align(region, dat, ppm, ali.mark)
ahtt <- ares$tdat
appm <- ares$appm
avg.c <- apply(ahtt, 1, mean)

# set new standard: 
ppm0 = appm
dat0 = ahtt
```

```{r,echo=FALSE}
print("Alignment results:")

region=which((appm>(-0.1))&(appm<0.05))
{plot(appm[region],ahtt[region,10],type="l",
      ylab="Intensity (a.u.)",xlab="Chemical shift (ppm)")
lines(appm[region],ahtt[region,2],col="red")
lines(appm[region],ahtt[region,3],col="green")
lines(appm[region],ahtt[region,4],col="blue")
lines(appm[region],ahtt[region,5],col="purple")
lines(appm[region],ahtt[region,6],col="orange")
lines(appm[region],ahtt[region,7],col="pink")
lines(appm[region],ahtt[region,8],col="yellow")
lines(appm[region],ahtt[region,9],col="skyblue")
lines(appm[region],ahtt[region,1],col="dark green")

}


```


###Baseline correction
```{r,warning=FALSE}
dat <- t(dat0)
ppm <- ppm0

dat.bl.rm <- baseline_removal(dat)
dat.bl <- dat.bl.rm$dat.bl
avg.bl <- apply(dat.bl, 2, mean)

```

```{r,echo=FALSE}
print("Baseline corretion results:")

{plot(ppm,avg.c,type="l",xlab="Chemical shift (ppm)",ylab="Intensity (a.u.)",col="black")
lines(ppm,avg.bl,col="red")
legend(2.8,0.0043,legend=c("Original","Base_corrected"),
       col=c("black","red"),lty=1,cex=0.8)}

```

###Keep informative spectra in 0.5-4.0ppm
```{r,results="hold"}
dat.bl1 <- dat.bl
dat.bl1 <- dat.bl1[, which(ppm < 4 & ppm >0.5)]
ppm1 <- ppm[which(ppm < 4 & ppm >0.5)]

dim(dat.bl1)
length(ppm1)

```


###Noise estimation
```{r}
nos.est <- Noise.est(dat.bl, pos.standar = c(0.08, 0.58), ppm)
nos <- nos.est * 5
nos

```

```{r}
qplot(ppm[which(ppm>0.5)], avg.bl[which(ppm>0.5)], geom = "line") + 
  geom_hline(yintercept = nos,col="red")+
  xlab("Chemical shift (ppm)")+
  ylab("Intensity (a.u.)")+
  scale_x_reverse()
```

###Quotient normalization
```{r}
qut_dat.bl1 <- PQ_norm_signal(t(dat.bl), method = "median", ppm, c(0.08, 0.58))
quot.bl1 <- qut_dat.bl1$quot
quot.final.bl1 <- qut_dat.bl1$quot.final
quot.final.bl1

```

```{r}
dat_pqnorm.bl1 <- matrix(NA, dim(dat.bl1)[1], dim(dat.bl1)[2])
for(i in 1 : length(quot.final.bl1)){
	dat_pqnorm.bl1[i, ] <- dat.bl1[i, ] / quot.final.bl1[i]
}

# set noise to 0
dat_pqnorm.bl2 <- dat_pqnorm.bl1
dat_pqnorm.bl2[which(dat_pqnorm.bl2 < nos)] <- 0

```


##SPA process:
### PACF
```{r,results="hold"}
dat = dat_pqnorm.bl1
ppm = ppm1
avg.d1 <- apply(dat_pqnorm.bl1, 2, mean)

pacf(avg.d1)
```

```{r,echo=FALSE}
print("Take pacf result as reference and set k.")
print("Here k is set to 7.")
```

```{r}
k=7
```

###Parameters for SPA
```{r}
span = 3
a1 = 0.8
a2 = 0.999
n.gam = 50
b2 = 0.99
kern.type = "tri_cube"
k = 7
n.tr <- dim(dat)[1]/2
n.cv <- 10

##set up a path to save output from SPA function
path=output_dir

```

###Run SPA
```{r,warning=FALSE}
ptm <- proc.time()
grp.res <- Gen.spa.clus(dat, ppm, k, span, a1, a2, n.gam, n.tr, n.cv, b2, kern.type,path)
proc.time() - ptm

#save out the SPA results for further reference
saveRDS(grp.res,paste(output_dir,"SPA_rds.rds",sep=""))
#grp.res=readRDS(paste(output_dir,"SPA_rds.rds",sep=""))

```

```{r}
#cluster member assigned to every ppm point
clus.mem <- grp.res$clus.mem

#separation of ppm points into clusters and background 
land.cut <- grp.res$land.cut 

##boundary label for every cluster
bond <- grp.res$bond

##average hump intensities in every cluster
ints <- grp.res$ints

##chosen optimal threshold for the correlation
gam <- grp.res$gam
```

```{r,echo=FALSE}

print("Total number of clusters: ")
```

```{r}
max(clus.mem)
```

```{r,echo=FALSE}
print("SPA results visualized in the spectra:(blue zones are the separations among clusters)")


base_size = 12
qplot(ppm, avg.d1, geom = "line", col = land.cut, ylab = "Intensity (a.u.)", xlab = "Chemical shift (ppm)")+
  scale_colour_gradient(low="blue", high="red") +
  theme_bw()+
  scale_x_reverse()+
theme(legend.position = "none", axis.title.x =  element_text(size = 15),axis.title.y = element_text(angle = 90, size = 15),
  axis.text.x = element_text(size = 15, vjust = 1), 
  axis.text.y = element_text(size = 15, hjust = 1),
  axis.ticks.x = element_line(), axis.ticks.y = element_line())+ theme(panel.background = element_blank())+ 
  theme(axis.line = element_line())+
  theme(legend.position = "none", axis.ticks = element_blank(), axis.text.x = 
element_text(size = base_size , angle = 0, hjust =0, colour = 
"black"), axis.text.y = element_text(size = base_size , angle = 0, hjust =1, colour = 
"black"), axis.ticks.x = element_line(), axis.ticks.y = element_line())+
  theme(panel.grid.major = element_blank())+
  theme(panel.background = element_blank())


```

##STOCSY process:
###Prepare input for STOCSY
```{r,results="hold"}
dat.spa <- ints  # intensities are calcualted by averaging the hump intensities with in that cluster.
cor.dat.spa <- cor(ints)
dim(ints)
dim(cor.dat.spa)
range(cor.dat.spa)


```

```{r}
myImagePlot2(cor.dat.spa)
```

###Heatmap for correlated clusters
```{r}
#set threshold for correlation among clusters
#Here set threshold as 0.8

a.8 <- cor.dat.spa
a.8[a.8 < 0.8] <- 0

myImagePlot2(a.8)

```

###Summarize and visulize correlated clusters
```{r}
##Have highly correlated clusters in list
a8 <- gen.J.couple(cor.dat.spa, .8)

##Visualize the positions of different clusters with 'clus' function
clus(id=c(5,9,11,17))

```

###Peak detection
```{r,echo=FALSE}
print("Select one of CWT or simple peak detection methods to proceed.")
```

####CWT peak detection
```{r}
##change the parameters based on different data
pks <- Peak_cwt(dat, ppm, thresh.scale = 1, scale.min = .5, 
                snr.min = 0.1, length.min=4, noise.span=NULL, noise.fun="quantile", 
                noise.min=NULL, n.octave.min=1, tolerance=0.0, holder=TRUE, process="msPeakCWT")


```

####Simple peak detection
```{r}
peaks=splus2R::peaks #specify that the peaks function is from splus2R package
pks <- Peak_simple(dat, ppm, thresh.scale = 10, snr = 3, snr.thresh=10)

```

####Extract detected peaks
```{r}
idx.pk <- pks$idx.pk
pk.ppm <- ppm[idx.pk]
```


###Summarize clusters and peaks
```{r,warning=FALSE}

cluster_peak=combine_cluster_peak(clus.mem,ppm,pk.ppm)
a8_summary=gen_summary_profile(cor_clus=a8,cluster_peak)

```


##Automatic metabolites identification
###Prepare inputs from SPA-STOCSY results
```{r}
##summarize peak lists in every SPA cluster
clus_mem=gen_SPA_peaks(profile=a8_summary,cluster_peak)
write.csv(clus_mem,paste(output_dir,"SPA_cluster_peaks.csv",sep=""))

##summarize highly-correlated clusters
spa_stocsy_corr=gen_stocsy_corr(profile=a8_summary)
write.csv(spa_stocsy_corr, paste(output_dir,"STOCSY_corr_clusters.csv",sep = ""))

```


###Prepare Chenomx library
```{r}
##load Chenomx library data
setwd(data_dir)
filename = "chx_lib_trunc.csv"

# Read data
Chx_lib <- read.csv(filename, header = T)
Chx_lib <- as.data.frame(Chx_lib)
colnames(Chx_lib) <- c("meta_name", "clus_ct")
meta_name <- as.character(unique(Chx_lib$meta_name))

head(Chx_lib)

```

```{r}
##shift to set upper and lower boundaries for each cluster
ppm_shift_thre = 0.025
new_lib <- Build_new(meta_name, ppm_shift_thre)
head(new_lib)

```


```{r}
##Load previous saved SPA_cluster_peaks.csv and STOCSY_corr_clusters.csv

setwd(output_dir)
clus_mem <- read.csv("SPA_cluster_peaks.csv", header = T)

col_name=NULL
for(nc in 1:(ncol(clus_mem)-1)){
  col_name=c(col_name,paste("pk",nc,sep=""))
}
colnames(clus_mem)=c("clus_id",col_name)

head(clus_mem)

spa_stocsy_corr <- read.csv('STOCSY_corr_clusters.csv', header = T)
spa_stocsy_corr=spa_stocsy_corr[,-1]
head(spa_stocsy_corr)

```


###Automatic identification on one group
```{r}
#take the third highly-correlated group for example

n=3
res <- Auto_dect_one(new_lib,as.numeric(spa_stocsy_corr[n,])[!is.na(as.numeric(spa_stocsy_corr[n,]))], clus_mem)

meta_ct <- res$meta_ct

# list the metabolite that has dect_rate above a set threshold: 
d.thre=0.55
meta_ct[which(meta_ct$dect_rate > d.thre), ]

```


###Automatic identification across all groups
```{r}
#set detection rate threshold
d.thre = 0.55
now <- proc.time()
cand_res <- FindMeta(new_lib, spa_stocsy_corr, clus_mem, d.thre)
proc.time()- now

all_nam <- unique(cand_res$all_name)
all_nam=all_nam[!(all_nam%in%c("No metabolite","No quanlified candidate"))]

write.csv(all_nam,paste(output_dir,"auto_identify_metabolites.csv",sep=""))

```

```{r,echo=FALSE}
cat(length(all_nam),"metabolites is automatically identified with the detection rate set as",d.thre)

```











